{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic reload of external .py scripts\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up cwd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local directory\n",
    "%cd /home/abaric/TakeLab/projects/retriever-sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Server directory\n",
    "%cd /home/abaric/retriever-sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.bertic_nn import Bertic_NN\n",
    "from models.fine_tune_framework import DLFramework\n",
    "\n",
    "from dataset_class.token_dataset import TokenDataset\n",
    "from data_transformation.label_transformation import label_transformation\n",
    "from data_transformation.token_transformation import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning BERTiÄ‡ model\n",
    "__________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up GPU\n",
    "\n",
    "if torch.cuda.is_available():   \n",
    "    # Choose between cuda:0 or cuda:1 based on GPU availability  \n",
    "    device = torch.device(\"cuda:1\")            \n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/gold_label/stone_gold_label.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['aggregated_sentiment'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tone label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['aggregated_tone'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace named entities with [MASK]\n",
    "\n",
    "masked_target = []\n",
    "\n",
    "for idx, row in data.iterrows():\n",
    "    text = row['text']\n",
    "    target = row['text'][row['ner_begin']:row['ner_end']]\n",
    "    masked_target.append(text.replace(target, '[MASK]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['masked_target_text'] = masked_target\n",
    "data['target_entity']  = '[MASK]'\n",
    "data['target_order'] = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "def split_dataset(X, y, test_proportion):\n",
    "    random_state =  random.randint(0, 1000)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state = random_state)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['document_id', 'text', 'ner', 'target_order', 'ner_type']]\n",
    "\n",
    "# Set sentiment labels as target labels\n",
    "label = 'aggregated_sentiment'\n",
    "y = data[label]\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_dataset(X, y, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test shapes\n",
    "print('Train and test shapes:\\n')\n",
    "print('X_train dimension = ', X_train.shape)\n",
    "print('y_train dimension = ', y_train.shape)\n",
    "\n",
    "print()\n",
    "\n",
    "print('X_test dimension = ', X_test.shape)\n",
    "print('y_test dimension = ', y_test.shape)\n",
    "\n",
    "print('..........................................')\n",
    "\n",
    "# Label distribution\n",
    "print(f'Train label distribution:\\n\\n{y_train.value_counts()}')\n",
    "print('\\n----------------------------------------')\n",
    "print(f'Test label distribution:\\n\\n{y_test.value_counts()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[585]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TokenDataset(X_train, y_train,\n",
    "                            token_transformation,\n",
    "                            label_transformation)\n",
    "\n",
    "\n",
    "test_dataset = TokenDataset(X_test, y_test,\n",
    "                            token_transformation,\n",
    "                            label_transformation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_selection.token_selection import *\n",
    "from feature_selection.token_aggregation import *\n",
    "from feature_selection.layer_strategy import *\n",
    "\n",
    "from data_transformation.feature_transformation import FeatureTransformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature transformation configs\n",
    "\n",
    "# Only target tokens - 1\n",
    "ft_11 = FeatureTransformation(only_target, average_aggregation, last_layer)\n",
    "ft_12 = FeatureTransformation(only_target, average_aggregation, second_to_last)\n",
    "ft_13 = FeatureTransformation(only_target, average_aggregation, sum_all)\n",
    "ft_14 = FeatureTransformation(only_target, average_aggregation, last_layer)\n",
    "ft_15 = FeatureTransformation(only_target, average_aggregation, mean_all)\n",
    "\n",
    "ft_1 = [ft_11, ft_12, ft_13, ft_14, ft_15]\n",
    "\n",
    "# TODO: Dodati masked i only_target + NER_type"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG_1\n",
    "config = {}\n",
    "config['batch_size'] = 16\n",
    "config['epochs'] = 50\n",
    "config['gradient_clipping'] = True\n",
    "\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set model + framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model\n",
    "bertic = Bertic_NN(ft_14, 769, 3)\n",
    "bertic.to(device)\n",
    "\n",
    "\n",
    "# Init train/eval module\n",
    "bertic_module = DLFramework(bertic, loss, config, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and eval model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertic_stats, clf_reports = bertic_module.run(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = bertic_stats['train_loss']\n",
    "test_loss = bertic_stats['val_loss']\n",
    "f1 = bertic_stats['val_f1']\n",
    "\n",
    "epochs = range(1, config['epochs']+1)\n",
    "\n",
    "plt.plot(epochs, train_loss, label='Train loss')\n",
    "plt.plot(epochs, test_loss, label='Test loss')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, f1, label='Test F1')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news_sentiment_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "580ed4c552a31dcc267fc5c50ca762b67fa9da7c5973d623a66aff125be5d655"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
